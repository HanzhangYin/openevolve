# Configuration for eigenvectors_complex task - Optimized Gemini Flash 2.5
# Achieved 1.64x AlgoTune Score with these settings

# General settings
max_iterations: 100
checkpoint_interval: 10
log_level: "INFO"
random_seed: 42
diff_based_evolution: true  # Best for Gemini models
max_code_length: 20000  # Increased from 10000 for deeper exploration

# LLM Configuration
llm:
  api_base: "https://openrouter.ai/api/v1"
  models:
    - name: "google/gemini-2.5-flash"
      weight: 1.0
  
  temperature: 0.4  # Optimal (better than 0.2, 0.6, 0.8)
  max_tokens: 128000  # Increased from 16000 for much richer context
  timeout: 150
  retries: 3

# Prompt Configuration - Optimal settings
prompt:
  system_message: |
    SETTING:
    You're an autonomous programmer tasked with solving a specific problem. You are to use the commands defined below to accomplish this task. Every message you send incurs a cost—you will be informed of your usage and remaining budget by the system.
    You will be evaluated based on the best-performing piece of code you produce, even if the final code doesn't work or compile (as long as it worked at some point and achieved a score, you will be eligible).
    Apart from the default Python packages, you have access to the following additional packages:
     - cryptography
     - cvxpy
     - cython
     - dace
     - dask
     - diffrax
     - ecos
     - faiss-cpu
     - hdbscan
     - highspy
     - jax
     - networkx
     - numba
     - numpy
     - ortools
     - pandas
     - pot
     - psutil
     - pulp
     - pyomo
     - python-sat
     - pythran
     - scikit-learn
     - scipy
     - sympy
     - torch
    Your primary objective is to optimize the `solve` function to run as as fast as possible, while returning the optimal solution.
    You will receive better scores the quicker your solution runs, and you will be penalized for exceeding the time limit or returning non-optimal solutions.

    Below you find the description of the task you will have to solve. Read it carefully and understand what the problem is and what your solver should do.

    You are an expert programmer specializing in matrix_operations algorithms. Your task is to improve the eigenvectors_complex algorithm implementation with baseline comparison.

    The problem description is:
    EigenvectorsComplex Task:

    Given a square matrix with real entries, the task is to compute its eigenpairs (eigenvalues and eigenvectors).
    Although the matrix is real, its eigenvalues may be complex.
    The goal is to compute the approximated eigenpairs and return:
      - A list of eigenvalues (complex numbers) sorted in descending order. The sorting order is defined as:
          first by the real part (in descending order), then by the imaginary part (in descending order).
      - A list of corresponding eigenvectors, each represented as a list of complex numbers, normalized to unit Euclidean norm.

    A valid solution is a tuple (eigenvalues, eigenvectors) where:
      - eigenvalues is a list of n numbers (complex or real) sorted as specified.
      - eigenvectors is an array of n eigenvectors, each of length n, representing the eigenvector corresponding to the eigenvalue at the same index.

    Focus on improving the solve method to correctly handle the input format and produce valid solutions efficiently. Your solution will be compared against the reference AlgoTune baseline implementation to measure speedup and correctness.
    
    
    


    PERFORMANCE OPTIMIZATION OPPORTUNITIES:
    You have access to high-performance libraries that can provide significant speedups:
    
    • **JAX** - JIT compilation for numerical computations
      Key insight: Functions should be defined outside classes for JIT compatibility
      For jnp.roots(), consider using strip_zeros=False in JIT contexts
    
    • **Numba** - Alternative JIT compilation, often simpler to use
    
    • **scipy optimizations** - Direct BLAS/LAPACK access and specialized algorithms
      Many scipy functions have optimized implementations worth exploring
    
    • **Vectorization** - Look for opportunities to replace loops with array operations
    
    EXPLORATION STRATEGY:
    1. Profile to identify bottlenecks first
    2. Consider multiple optimization approaches for the same problem
    3. Try both library-specific optimizations and algorithmic improvements
    4. Test different numerical libraries to find the best fit

    
    PROBLEM-SPECIFIC OPTIMIZATION HINTS:
    Computing eigenvectors of complex matrices - PROVEN OPTIMIZATIONS (1.4x speedup achieved):
    
    **KEY INSIGHT**: The input matrix is REAL (not complex), but the original algorithm treats it as complex.
    Post-processing (sorting/normalization) can be heavily optimized.
    
    **VECTORIZED POST-PROCESSING** (Most Effective - 35% speedup):
    • Use numpy.argsort instead of Python's sort for eigenvalue ordering
    • Vectorize normalization using broadcasting instead of loops
    • Use advanced indexing to avoid memory copies
    
    **OPTIMIZED IMPLEMENTATION**:
    ```python
    # Use numpy.linalg.eig (faster than scipy for small/medium matrices)
    eigenvalues, eigenvectors = np.linalg.eig(A)
    
    # VECTORIZED SORTING: Use numpy.lexsort (much faster than Python sort)
    sort_indices = np.lexsort((-eigenvalues.imag, -eigenvalues.real))
    sorted_eigenvectors = eigenvectors[:, sort_indices]  # No copying
    
    # VECTORIZED NORMALIZATION: All columns at once
    norms = np.linalg.norm(sorted_eigenvectors, axis=0)
    valid_mask = norms > 1e-12
    sorted_eigenvectors[:, valid_mask] /= norms[valid_mask]
    
    # EFFICIENT CONVERSION: Use .T.tolist() instead of Python loops
    return sorted_eigenvectors.T.tolist()
    ```
    
    **MEMORY LAYOUT OPTIMIZATION** (5-10% additional on M4):
    • Use C-contiguous arrays for numpy.linalg.eig
    • Code: A = np.ascontiguousarray(A.astype(np.float64))
    • Detect Apple Silicon: platform.processor() == 'arm' and platform.system() == 'Darwin'
    
    **KEY OPTIMIZATIONS**:
    • Replace Python loops with numpy vectorized operations
    • Eliminate list() and zip() operations in sorting
    • Use advanced indexing instead of creating copies
    • Stay in numpy throughout, convert to list only at the end
    
    **AVOID**:
    • Python sorting with lambda functions - extremely slow
    • eigenvectors.T - creates unnecessary matrix copy
    • Loop-based normalization - vectorize instead
    • scipy.linalg.eig for small matrices - has more overhead than numpy
    
  num_top_programs: 10     # Increased from 3-5 for richer learning context
  num_diverse_programs: 5  # Increased from 2 for more diverse exploration
  include_artifacts: true  # +20.7% improvement

# Database Configuration
database:
  population_size: 1000
  archive_size: 100
  num_islands: 4
  
  # Selection parameters - Optimal ratios
  elite_selection_ratio: 0.1   # 10% elite
  exploration_ratio: 0.3       # 30% exploration
  exploitation_ratio: 0.6      # 60% exploitation
  
  # NO feature_dimensions - let it use defaults based on evaluator metrics
  feature_bins: 10
  
  # Migration parameters
  migration_interval: 20
  migration_rate: 0.1  # Better than 0.2

# Evaluator Configuration
evaluator:
  timeout: 200
  max_retries: 3
  
  # Cascade evaluation
  cascade_evaluation: true
  cascade_thresholds: [0.5, 0.8]
  
  # Parallel evaluations
  parallel_evaluations: 1

# AlgoTune task-specific configuration
algotune:
  num_trials: 5
  data_size: 25
  timeout: 300
  num_runs: 3
  warmup_runs: 1
